{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b8068-1c78-4bd7-909b-c115c486ea5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lisbeth\\miniforge3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "Recognized: MGP21UCS110\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "Recognized: MGP21UCS111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "Recognized: MGP21UCS108\n",
      "Identified identities and output frames written to C:\\Users\\Lisbeth\\input\\op_20240510_223841.pdf\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from numpy import asarray, expand_dims\n",
    "from keras_facenet import FaceNet\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from PIL import Image as PILImage\n",
    "from datetime import datetime\n",
    "\n",
    "HaarCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "MyFaceNet = FaceNet()\n",
    "\n",
    "# Load the face database\n",
    "with open(\"data.pkl\", \"rb\") as myfile:\n",
    "    database = pickle.load(myfile)\n",
    "\n",
    "# Define the maximum number of identities per page\n",
    "MAX_IDENTITIES_PER_PAGE = 10\n",
    "\n",
    "# Function to write identified identities and output frame into a PDF\n",
    "def write_to_pdf(pages, output_file):\n",
    "    c = canvas.Canvas(output_file, pagesize=letter)\n",
    "\n",
    "    # Loop through each page\n",
    "    for page_num, (op, resized_image_path) in enumerate(pages, start=1):\n",
    "        y_offset = 750  # Initial Y offset for writing text\n",
    "\n",
    "        # Write identified identities\n",
    "        for identity in op:\n",
    "            c.drawString(100, y_offset, f\"Identity: {identity}\")\n",
    "            y_offset -= 20  # Move to the next line\n",
    "\n",
    "        # Insert resized image into PDF\n",
    "        img = PILImage.open(resized_image_path)\n",
    "        img_width, img_height = img.size\n",
    "        aspect_ratio = img_height / img_width\n",
    "        target_width = 400  # Adjust this value as needed\n",
    "        target_height = int(target_width * aspect_ratio)\n",
    "        img.thumbnail((target_width, target_height))\n",
    "        c.drawInlineImage(resized_image_path, 100, y_offset - target_height, width=target_width, height=target_height)\n",
    "\n",
    "        # Show page number\n",
    "        c.drawString(100, 50, f\"Page {page_num}\")\n",
    "\n",
    "        c.showPage()  # End the current page\n",
    "\n",
    "    c.save()\n",
    "\n",
    "# Function to process the image\n",
    "def process_image(image_path):\n",
    "    try:\n",
    "        # Read the image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(\"Failed to read the image file. Please make sure the path is correct and the file exists.\")\n",
    "            return\n",
    "\n",
    "        # Convert BGR image to RGB\n",
    "        frame_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces\n",
    "        wajah = HaarCascade.detectMultiScale(frame_rgb, 1.1, 4)\n",
    "\n",
    "        recognized_ids = set()\n",
    "        op = []\n",
    "        pages = []  # Initialize pages list\n",
    "\n",
    "        for (x, y, w, h) in wajah:\n",
    "            # Extract the face region\n",
    "            face = frame_rgb[y:y + h, x:x + w]\n",
    "\n",
    "            # Resize the face image to match the input size of FaceNet\n",
    "            face_resized = cv2.resize(face, (160, 160))\n",
    "\n",
    "            # Convert the face image to an array and add a batch dimension\n",
    "            face_array = np.expand_dims(face_resized, axis=0)\n",
    "\n",
    "            # Get the embedding of the face using FaceNet model\n",
    "            face_embedding = MyFaceNet.embeddings(face_array)\n",
    "\n",
    "            min_dist = 100\n",
    "            identity = 'unknown'\n",
    "\n",
    "            for key, value in database.items():\n",
    "                dist = np.linalg.norm(value - face_embedding)\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    identity = key\n",
    "\n",
    "            # Check if the minimum distance is below the threshold and if the ID has not been recognized before\n",
    "            if min_dist < 0.8:\n",
    "                # Face recognized, print the identity\n",
    "                print(\"Recognized:\", identity)\n",
    "                recognized_ids.add(identity)\n",
    "\n",
    "                # Append the identity to the list\n",
    "                op.append(identity)\n",
    "\n",
    "                # Add the current page to the list if it has reached the maximum number of identities per page\n",
    "                if len(op) >= MAX_IDENTITIES_PER_PAGE:\n",
    "                    pages.append((op, 'resized_output_frame.jpg'))\n",
    "                    op = []\n",
    "\n",
    "                cv2.putText(img, identity, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            else:\n",
    "                # Face not recognized, mark as unknown\n",
    "                cv2.putText(img, \"Unknown\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                \n",
    "        # Resize the image\n",
    "        scale_percent = 40  # Adjust this value to change the scaling percentage\n",
    "        width = int(img.shape[1] * scale_percent / 100)\n",
    "        height = int(img.shape[0] * scale_percent / 100)\n",
    "        resized_image = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Save the resized image\n",
    "        resized_image_path = \"resized_image.jpg\"\n",
    "        cv2.imwrite(resized_image_path, resized_image)\n",
    "\n",
    "        # Add the last page if there are remaining identities\n",
    "        if op:\n",
    "            pages.append((op, resized_image_path))\n",
    "\n",
    "        # Generate the PDF with identified identities and output frames\n",
    "        if pages:\n",
    "            output_dir = os.path.dirname(image_path)\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_file = os.path.join(output_dir, f\"op_{timestamp}.pdf\")\n",
    "            write_to_pdf(pages, output_file)\n",
    "            print(f\"Identified identities and output frames written to {output_file}\")\n",
    "\n",
    "        # Display the resized image\n",
    "        cv2.imshow('resized_image', resized_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "# Input path\n",
    "input_path =\"C:\\\\Users\\\\Lisbeth\\\\input\\\\WhatsApp Image 2024-04-30 at 23.55.10_5a5f545f.jpg\"\n",
    "\n",
    "# Check if input path is an image or a video file\n",
    "if os.path.isfile(input_path):\n",
    "    _, file_extension = os.path.splitext(input_path)\n",
    "    if file_extension.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.gif']:\n",
    "        process_image(input_path)\n",
    "    elif file_extension.lower() in ['.mp4', '.avi', '.mov', '.mkv']:\n",
    "        process_video(input_path)\n",
    "    else:\n",
    "        print(\"Unsupported file format.\")\n",
    "else:\n",
    "    print(\"Input path does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa41448b-3557-44af-8688-160a86e2feac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e709951b-3fce-4f60-b04f-0d121d0a9a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
